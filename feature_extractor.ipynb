{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import string\n",
    "import os\n",
    "import copy\n",
    "import shutil\n",
    "import json\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression as lr \n",
    "from sklearn import metrics\n",
    "import cv2\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    \n",
    "    \"original\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/\",\n",
    "        \"plot_color\" : \"C0\",\n",
    "        \"notes\" : \"using the original CUB images, no center crop, then resize to 224\",\n",
    "    },\n",
    "    \"center_crop\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/squared_bounding_box/\",\n",
    "        \"plot_color\" : \"C1\",\n",
    "        \"notes\" : \"using the original CUB images, with a 256 center crop then resize to 224.\"\n",
    "    },\n",
    "    \"bounding_box\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/bounding_box/\",\n",
    "        \"plot_color\" : \"C2\",\n",
    "        \"notes\" : \"using the original CUB images, with a 256 center crop then resize to 224.\"\n",
    "    },\n",
    "    \"segmentation\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/segmentation/\",\n",
    "        \"plot_color\" : \"C3\",\n",
    "        \"notes\" : \"using the original CUB images, with a 256 center crop then resize to 224.\"\n",
    "    },\n",
    "    \"bounding_box_segmentation\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/bounding_box_segmentation/\",\n",
    "        \"plot_color\" : \"C4\",\n",
    "        \"notes\" : \"using the original CUB images, with a 256 center crop then resize to 224.\"\n",
    "    },\n",
    "    \"simple_rectification\" : {\n",
    "        \"image_dir\" : \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/simple_rectification/\",\n",
    "        \"plot_color\" : \"C5\",\n",
    "        \"notes\" : \"using the original CUB images, with a 256 center crop then resize to 224.\"\n",
    "    },\n",
    "   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation \n",
    "\n",
    "# Don't forget that CUB labels start at 1, not 0! Might need to account for this because you do want the labels to start from 0\n",
    "# So subtract 1 when you load in the CUB files...\n",
    "\n",
    "class_txt = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/images.txt\"\n",
    "image_class_labels = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/image_class_labels.txt\"\n",
    "train_test_split = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/train_test_split.txt\"\n",
    "\n",
    "# cub label to list of all image ids \n",
    "# e.g. {1 : [1, 2, 3, 4, 5, 6, 7], 2: [33, 34, 34]}\n",
    "label_to_image_ids = {}\n",
    "with open(image_class_labels) as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines:\n",
    "        line = line.rstrip('\\n')\n",
    "\n",
    "        img_id = int(line.split(' ')[0])\n",
    "        label = int(line.split(' ')[1]) - 1\n",
    "        \n",
    "        next_label = label + 1\n",
    "        if(label == next_label):\n",
    "            label_to_image_ids[next_label] = img_id\n",
    "\n",
    "        else:\n",
    "            if(label in label_to_image_ids.keys()):\n",
    "                label_to_image_ids[label].append(img_id)\n",
    "                          \n",
    "            else:\n",
    "                label_to_image_ids[label]= [img_id]\n",
    "    f.close()    \n",
    "    \n",
    "# cub label to list of image ids for training \n",
    "# e.g. {1 : [1, 2, 3, 4, 5, 6, 7], 2: [33, 34, 34]}\n",
    "label_to_training_image_ids = {}\n",
    "with open(train_test_split) as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines:\n",
    "        line = line.rstrip('\\n')\n",
    "\n",
    "        img_id = int(line.split(' ')[0])\n",
    "\n",
    "        determinant = int(line.split(' ')[1])\n",
    "\n",
    "        if(determinant == 1): # this is a training img\n",
    "            for key, value in label_to_image_ids.items():\n",
    "\n",
    "                if img_id in value:\n",
    "                    if(key in label_to_training_image_ids.keys()):\n",
    "                        label_to_training_image_ids[key].append(img_id)\n",
    "                    else:\n",
    "                        label_to_training_image_ids[key] = [img_id]\n",
    "                    break\n",
    "    f.close()\n",
    "    \n",
    "# image id to fp\n",
    "# e.g. {1 : \"001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\", 2 : \"001.Black_footed_Albatross/Black_Footed_Albatross_0009_34.jpg\"}\n",
    "cub_image_id_to_fp = {}\n",
    "with open(class_txt) as f:\n",
    "    Lines = f.readlines()\n",
    "    for line in Lines:\n",
    "        line = line.rstrip('\\n')\n",
    "        img_id = int(line.split(' ')[0])\n",
    "        fp = line.split(' ')[1]\n",
    "        \n",
    "        cub_image_id_to_fp[img_id] = fp\n",
    "        \n",
    "    f.close()\n",
    "def get_image_fp_for_image_dir(image_id, image_dir):\n",
    "    \"\"\" Return the file path for `image_id` in the provided image directory\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the filepath for the image_id\n",
    "    return os.path.join(image_dir, cub_image_id_to_fp[image_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is used from https://github.com/visipedia/newt/tree/main/benchmark\n",
    "PYTORCH_PRETRAINED_MODELS_DIR = '/Users/madisonvanhorn/Documents/iNaturalist_2017/pretrained-models/cvpr21_newt_pretrained_models/pt/'\n",
    "PYTORCH = \"pytorch\"\n",
    "\n",
    "# Pretraining Datasets\n",
    "IMAGENET = \"ImageNet\"\n",
    "INAT2021 = \"iNat2021\"\n",
    "INAT2018 = \"iNat2018\"\n",
    "\n",
    "# Training Objectives\n",
    "SUPERVISED = \"Supervised\"\n",
    "MOCO_V2 = \"MOCO v2\"\n",
    "SWAV = \"SwAV\"\n",
    "SIMCLR = \"SimCLR\"\n",
    "SIMCLR_V2 = \"SimCLR v2\"\n",
    "\n",
    "# Models\n",
    "RESNET50 = \"ResNet50\"\n",
    "model_specs = {\n",
    "\n",
    "    \"imagenet\": {\n",
    "        \"name\" : \"imagenet_supervised\",\n",
    "        \"display_name\" : \"ImageNet Supervised (pytorch)\",\n",
    "        \"color\" : \"black\",\n",
    "        \"format\" : PYTORCH,\n",
    "        \"backbone\" : RESNET50,\n",
    "        \"weights\" : None,\n",
    "        \"training_dataset\" : IMAGENET,\n",
    "        \"train_objective\" : SUPERVISED,\n",
    "        \"pretrained_weights\" : None\n",
    "    },\n",
    "\n",
    "    \"inat2021\": {\n",
    "        \"name\" : \"inat2021_supervised\",\n",
    "        \"display_name\" : \"iNat2021 Supervised\",\n",
    "        \"color\" : \"C9\",\n",
    "        \"format\" : PYTORCH,\n",
    "        \"backbone\" : RESNET50,\n",
    "        \"weights\" : PYTORCH_PRETRAINED_MODELS_DIR + 'inat2021_supervised_large.pth.tar',\n",
    "        \"training_dataset\" : INAT2021,\n",
    "        \"train_objective\" : SUPERVISED,\n",
    "        \"pretrained_weights\" : IMAGENET\n",
    "    },\n",
    "\n",
    "    \"inat2018\":{\n",
    "        \"name\" : \"inat2018_supervised\",\n",
    "        \"display_name\" : \"iNat2018 Supervised\",\n",
    "        \"color\" : \"C7\",\n",
    "        \"format\" : PYTORCH,\n",
    "        \"backbone\" : RESNET50,\n",
    "        \"weights\" : PYTORCH_PRETRAINED_MODELS_DIR + 'inat2018_supervised.pth.tar',\n",
    "        \"training_dataset\" : INAT2018,\n",
    "        \"train_objective\" : SUPERVISED,\n",
    "        \"pretrained_weights\" : IMAGENET\n",
    "    },\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model\n",
    "Initialize model and remove the last fully connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change model name to your discretion \n",
    "\n",
    "model_name = 'inat2021'\n",
    "\n",
    "model = models.resnet50(pretrained=False)\n",
    "model_type = model_specs[model_name]['name']\n",
    "model_weights_fp = model_specs[model_name]['weights']\n",
    "\n",
    "\n",
    "# This model was actually trained with 10000 classes for the fc layer\n",
    "# but only 8142 (the number in inat2018) were actually updated\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10000)\n",
    "checkpoint = torch.load(model_weights_fp, map_location=\"cpu\")\n",
    "msg = model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
    "\n",
    "# Detect if we have a GPU available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model_ft.cuda()\n",
    "\n",
    "# strip the last layer\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the test features for each input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the test image ids and test labels\n",
    "# e.g. {8 : 1, 9 : 1}\n",
    "test_image_id_to_label = {}\n",
    "    \n",
    "# Get the training image ads and labels\n",
    "train_test_split = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/train_test_split.txt\"\n",
    "      \n",
    "with open(train_test_split) as f:\n",
    "    Lines = f.readlines()\n",
    "\n",
    "    for line in Lines:\n",
    "        line = line.rstrip('\\n')\n",
    "\n",
    "        img_id = int(line.split(' ')[0])\n",
    "        test_id = int(line.split(' ')[1])\n",
    "\n",
    "        if (test_id == 0): # Add to training dictionary  \n",
    "            for key, value in label_to_image_ids.items():\n",
    "                if img_id in value:\n",
    "                    test_image_id_to_label[img_id] = key\n",
    "                    break\n",
    "                                 \n",
    "    f.close()   \n",
    "\n",
    "for experiment_name, experiment_settings in experiments.items():\n",
    "    print(experiment_name)\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    \n",
    "    for test_image_id, test_label in test_image_id_to_label.items():\n",
    "        img_directory = experiment_settings['image_dir'] +'test/'\n",
    "\n",
    "        # Get the file path to the image for this specific input type\n",
    "        image_fp = get_image_fp_for_image_dir(test_image_id, img_directory)\n",
    "\n",
    "        # Normalize Data\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "                \n",
    "        # Extract feature...\n",
    "        model.eval()\n",
    "        \n",
    "        im = Image.open(image_fp).convert('RGB')\n",
    "        im = transform(im).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_feature = model(im.unsqueeze(0)).squeeze() # output now has the features corresponding to input x\n",
    "\n",
    "            X_test.append(image_feature.cpu().data.numpy())\n",
    "            y_test.append(test_label)\n",
    "    \n",
    "    experiment_settings['X_test'] = X_test\n",
    "    experiment_settings['y_test'] = y_test  \n",
    "    \n",
    "    #Save features\n",
    "    testing_features = '/Users/madisonvanhorn/Documents/iNaturalist_2017/features_inat2021/' + 'test_features_' + experiment_name + '.npz'\n",
    "    np.savez(testing_features, features = np.array(X_test), labels = np.array(y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the train features for each input type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the train image ids and train labels\n",
    "# e.g. {8 : 1, 9 : 1}\n",
    "\n",
    "train_image_id_to_label = {}\n",
    "\n",
    "# Get the training image ads and labels\n",
    "train_test_split = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/train_test_split.txt\"\n",
    "      \n",
    "with open(train_test_split) as f:\n",
    "    Lines = f.readlines()\n",
    "\n",
    "    for line in Lines:\n",
    "        line = line.rstrip('\\n')\n",
    "\n",
    "        img_id = int(line.split(' ')[0])\n",
    "        train_id = int(line.split(' ')[1])\n",
    "\n",
    "        if (train_id == 1): # Add to training dictionary  \n",
    "            for key, value in label_to_training_image_ids.items():   \n",
    "                if img_id in value:\n",
    "                    train_image_id_to_label[img_id] = key \n",
    "                    break\n",
    "                    \n",
    "    f.close()       \n",
    "                  \n",
    "for experiment_name, experiment_settings in experiments.items():\n",
    "    print('Experiment name: ' +str(experiment_name))\n",
    "    X_train = {}\n",
    "    y_train = {}\n",
    "\n",
    "    for train_image_id, train_label in train_image_id_to_label.items():\n",
    "\n",
    "        # Get the file path to the image for this specific input type\n",
    "        img_directory = experiment_settings['image_dir'] +'train/'\n",
    "\n",
    "        image_fp = get_image_fp_for_image_dir(train_image_id, img_directory)\n",
    "\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        model.eval()      \n",
    "        im = Image.open(image_fp).convert('RGB')\n",
    "        im = transform(im).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_feature = model(im.unsqueeze(0)).squeeze() # output now has the features corresponding to input x  \n",
    "            X_train[train_image_id] = image_feature.cpu().data.numpy()                               \n",
    "            y_train[train_image_id] = train_label\n",
    "            \n",
    "    experiment_settings['X_train'] = X_train\n",
    "    experiment_settings['y_train'] = y_train\n",
    "\n",
    "    #Save features\n",
    "    training_features = '/Users/madisonvanhorn/Documents/iNaturalist_2017/features_inat2021/' + 'train_features_' + experiment_name + '.npz'\n",
    "    np.savez(training_features, features = np.array(X_train), labels = np.array(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. {1 : {'orginal' : [0.04, 0.05, 0.05], 'center_crop' : [0.1, 0.09, 0.09], ...}, '2' : {'original' : [...]}}\n",
    "k_shot_accuracy_results = {}\n",
    "correct_img_classification = {}\n",
    "# Outer loop for the k-shot learning\n",
    "for number_of_training_images in [1, 3, 5, 10, 20, 30]:\n",
    "    \n",
    "    k_shot_accuracy_results[number_of_training_images] = {experiment_name : [] for experiment_name in experiments}\n",
    "    \n",
    "    k_shot_accuracy_results[number_of_training_images]['selected_images'] = [] # this will save which random images (i.e dataset) were selected for each trial run\n",
    "    \n",
    "    # We want to repeat each experiment X times\n",
    "    for i in range(10):\n",
    "        \n",
    "        # Create the dataset dataset\n",
    "        exp_cub_label_to_trainning_images = {}\n",
    "        for label in range(200):\n",
    "            num_to_sample = min(len(label_to_training_image_ids[label]), number_of_training_images)\n",
    "            exp_cub_label_to_trainning_images[label] = sample(label_to_training_image_ids[label], num_to_sample)\n",
    "        \n",
    "        k_shot_accuracy_results[number_of_training_images]['selected_images'].append(exp_cub_label_to_trainning_images)\n",
    "        \n",
    "        # Now go through each input setting and use the randomly selected dataset to run an experiment\n",
    "        for experiment_name, experiment_settings in experiments.items():\n",
    "            \n",
    "            # Extract train features\n",
    "            X_train = []\n",
    "            y_train = []\n",
    "            \n",
    "            for label, label_image_ids in exp_cub_label_to_trainning_images.items():    \n",
    "  \n",
    "                for image_id in label_image_ids:\n",
    "                    image_feature = experiment_settings['X_train'][image_id]\n",
    "                    X_train.append(image_feature)\n",
    "                    y_train.append(label)               \n",
    "            \n",
    "            \n",
    "            # Train linear model\n",
    "            clf = lr(max_iter=1000,C = 0.025)\n",
    "            clf.fit(X_train, y_train)\n",
    "            \n",
    "            # Evaluate classifier\n",
    "            y_pred = clf.predict(experiment_settings['X_test'])\n",
    "            \n",
    "            print(experiment_name)\n",
    "            acc = metrics.accuracy_score(experiment_settings['y_test'], y_pred)\n",
    "            print(\"Accuracy: \", acc)\n",
    "          \n",
    "            k_shot_accuracy_results[number_of_training_images][experiment_name].append(float(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save off the results!\n",
    "\n",
    "with open('/Users/madisonvanhorn/Documents/iNaturalist_2017/features/experiment_features_inat2021.pkl', 'wb') as fp:\n",
    "    pickle.dump(experiments, fp)\n",
    "    \n",
    "with open(\"/Users/madisonvanhorn/Documents/iNaturalist_2017/report/results_inat2021.json\", \"w\") as f:\n",
    "    json.dump(k_shot_accuracy_results, f) # WATCH OUT: json complains about saving numpy data, so you might have to convert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display figure of bird with implemented experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"/Users/madisonvanhorn/Documents/iNaturalist_2017/CUB_200_2011/CUB_200_2011/\"\n",
    "train_dir = main_dir + \"train/\"\n",
    "img_dir=np.random.choice(os.listdir(train_dir))\n",
    "img_name = np.random.choice(os.listdir(train_dir +img_dir))\n",
    "\n",
    "original = main_dir + 'train/' + img_dir + '/' + img_name\n",
    "center_crop_dir = main_dir + 'squared_bounding_box/' +'train/' + img_dir + '/' + img_name\n",
    "bounding_box_dir = main_dir + 'bounding_box/' + 'train/' + img_dir + '/' + img_name\n",
    "bounding_box_seg_dir = main_dir + 'bounding_box_segmentation/' + 'train/' + img_dir + '/' + img_name\n",
    "segmentation_dir = main_dir + 'segmentation/' + 'train/' + img_dir + '/' + img_name\n",
    "orientation_rect = main_dir + 'simple_rectification/' + 'train/' + img_dir + '/' + img_name\n",
    "\n",
    "\n",
    "f, axarr = plt.subplots(2,3, figsize=(15,8))\n",
    "axarr[0,0].title.set_text('Original')\n",
    "axarr[0,0].imshow(cv2.cvtColor(cv2.imread(original),cv2.COLOR_BGR2RGB )) # Whole Image\n",
    "\n",
    "axarr[0,1].title.set_text('Bounding Box')\n",
    "axarr[0,1].imshow(cv2.cvtColor(cv2.imread(bounding_box_dir),cv2.COLOR_BGR2RGB)) # Bounding Boxes\n",
    "\n",
    "axarr[0,2].title.set_text('Segmentation')\n",
    "axarr[0,2].imshow(cv2.cvtColor(cv2.imread(segmentation_dir),cv2.COLOR_BGR2RGB)) # Segmentation Background\n",
    "\n",
    "axarr[1,0].title.set_text('Simple Rectification')\n",
    "axarr[1,0].imshow(cv2.cvtColor(cv2.imread(orientation_rect), cv2.COLOR_BGR2RGB)) # Simple Rectified\n",
    "\n",
    "axarr[1,1].title.set_text('Bounding Box Segmentation')\n",
    "axarr[1,1].imshow(cv2.cvtColor(cv2.imread(bounding_box_seg_dir), cv2.COLOR_BGR2RGB)) # Bounding Box Segmentation \n",
    "\n",
    "axarr[1,2].title.set_text('Squared Bounding Box')\n",
    "axarr[1,2].imshow(cv2.cvtColor(cv2.imread(center_crop_dir), cv2.COLOR_BGR2RGB)) # Center Crop \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display plot showing the results from each K-Shot experiment with the various data augmentation experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5, 10, 20, 30]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "y = [np.mean(k_shot_accuracy_results[1]['original']), np.mean(k_shot_accuracy_results[3]['original']),\n",
    "     np.mean(k_shot_accuracy_results[5]['original']),np.mean(k_shot_accuracy_results[10]['original']),\n",
    "     np.mean(k_shot_accuracy_results[20]['original']),np.mean(k_shot_accuracy_results[30]['original']) ]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='Original')\n",
    "y = [np.mean(k_shot_accuracy_results[1]['center_crop']), np.mean(k_shot_accuracy_results[3]['center_crop']),\n",
    "     np.mean(k_shot_accuracy_results[5]['center_crop']),np.mean(k_shot_accuracy_results[10]['center_crop']),\n",
    "     np.mean(k_shot_accuracy_results[20]['center_crop']),np.mean(k_shot_accuracy_results[30]['center_crop']) ]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='Center Crop')\n",
    "y = [np.mean(k_shot_accuracy_results[1]['bounding_box']), np.mean(k_shot_accuracy_results[3]['bounding_box']),\n",
    "     np.mean(k_shot_accuracy_results[5]['bounding_box']),np.mean(k_shot_accuracy_results[10]['bounding_box']),\n",
    "     np.mean(k_shot_accuracy_results[20]['bounding_box']),np.mean(k_shot_accuracy_results[30]['bounding_box'])]\n",
    "plt.plot(x, y, marker=\"o\", label='Bounding Box')\n",
    "y = [np.mean(k_shot_accuracy_results[1]['segmentation']), np.mean(k_shot_accuracy_results[3]['segmentation']),\n",
    "     np.mean(k_shot_accuracy_results[5]['segmentation']),np.mean(k_shot_accuracy_results[10]['segmentation']),\n",
    "     np.mean(k_shot_accuracy_results[20]['segmentation']),np.mean(k_shot_accuracy_results[30]['segmentation'])]\n",
    "     \n",
    "plt.plot(x, y, marker=\"o\", label='Segmentation')\n",
    "\n",
    "y = [np.mean(k_shot_accuracy_results[1]['bounding_box_segmentation']), np.mean(k_shot_accuracy_results[3]['bounding_box_segmentation']),\n",
    "     np.mean(k_shot_accuracy_results[5]['bounding_box_segmentation']),np.mean(k_shot_accuracy_results[10]['bounding_box_segmentation']),\n",
    "     np.mean(k_shot_accuracy_results[20]['bounding_box_segmentation']),np.mean(k_shot_accuracy_results[30]['bounding_box_segmentation'])]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='Bounding Box Segmentation')\n",
    "\n",
    "y = [np.mean(k_shot_accuracy_results[1]['simple_rectification']), np.mean(k_shot_accuracy_results[3]['simple_rectification']),\n",
    "     np.mean(k_shot_accuracy_results[5]['simple_rectification']),np.mean(k_shot_accuracy_results[10]['simple_rectification']),\n",
    "     np.mean(k_shot_accuracy_results[20]['simple_rectification']),np.mean(k_shot_accuracy_results[30]['simple_rectification'])]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='Simple Rectification')\n",
    "\n",
    "plt.xlabel('Number of Training Samples Used Per Class')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.title('Average Test Set Accuracy for K-Shot Learning with iNat2021 Feature Extractor')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display plot after collecting all three feature extractors' accuracies\n",
    "Will need to change the above code to retrieve all three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Users/madisonvanhorn/Documents/iNaturalist_2017/final-product/log_reg_results/results_iNat2021_logreg.pkl\", \"rb\") as f:\n",
    "    k_shot_accuracy_results_iNat2021 = pickle.load(f) \n",
    "with open(\"Users/madisonvanhorn/Documents/iNaturalist_2017/final-product/log_reg_results/results_iNat2018_logreg.pkl\", \"rb\") as f:\n",
    "    k_shot_accuracy_results_iNat2018 = pickle.load(f) \n",
    "with open(\"Users/madisonvanhorn/Documents/iNaturalist_2017/final-product/log_reg_results/results_imagenet_logreg.pkl\", \"rb\") as f:\n",
    "    k_shot_accuracy_results_imagenet = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1, 3, 5, 10, 20, 30]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "y = [np.mean(k_shot_accuracy_results_iNat2021[1]['original']), np.mean(k_shot_accuracy_results_iNat2021[3]['original']),\n",
    "     np.mean(k_shot_accuracy_results_iNat2021[5]['original']),np.mean(k_shot_accuracy_results_iNat2021[10]['original']),\n",
    "     np.mean(k_shot_accuracy_results_iNat2021[20]['original']),np.mean(k_shot_accuracy_results_iNat2021[30]['original']) ]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='iNat2021 Original')\n",
    "y = [np.mean(k_shot_accuracy_results_iNat2018[1]['original']), np.mean(k_shot_accuracy_results_iNat2018[3]['original']),\n",
    "     np.mean(k_shot_accuracy_results_iNat2018[5]['original']),np.mean(k_shot_accuracy_results_iNat2018[10]['original']),\n",
    "     np.mean(k_shot_accuracy_results_iNat2018[20]['original']),np.mean(k_shot_accuracy_results_iNat2018[30]['original']) ]\n",
    "\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='iNat2018 Original')\n",
    "y = [np.mean(k_shot_accuracy_results_imagenet[1]['original']), np.mean(k_shot_accuracy_results_imagenet[3]['original']),\n",
    "     np.mean(k_shot_accuracy_results_imagenet[5]['original']),np.mean(k_shot_accuracy_results_imagenet[10]['original']),\n",
    "     np.mean(k_shot_accuracy_results_imagenet[20]['original']),np.mean(k_shot_accuracy_results_imagenet[30]['original']) ]\n",
    "\n",
    "plt.plot(x, y, marker=\"o\", label='ImageNet Original')\n",
    "\n",
    "plt.xlabel('Number of Training Samples Used Per Class')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(x)\n",
    "plt.title('K-Shot Learning for Fine-Grained Classification on All Three Feature Extractors')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}